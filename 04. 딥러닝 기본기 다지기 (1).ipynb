{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21650ee4",
   "metadata": {},
   "source": [
    "**기본 세팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9c44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ed5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='NanumGothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4c91b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1ebca",
   "metadata": {},
   "source": [
    "# 10. 모델 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3fb62",
   "metadata": {},
   "source": [
    "이번 챕터에서는 폐암 수술 환자 데이터를 이용해서 생존율을 예측할 것이다.\n",
    "\n",
    "딥러닝을 이용해서 진행할 것이고 각 코드가 어떤 역할을 하는지 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b48604",
   "metadata": {},
   "source": [
    "## 10.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef711ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 폐암 수술 환자 데이터\n",
    "Data_set = np.loadtxt(\"deeplearning/dataset/ThoraricSurgery.csv\", delimiter = \",\")\n",
    "Data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eeb0fe",
   "metadata": {},
   "source": [
    "- 우선 csv파일로 된 데이터를 불러왔다.\n",
    "\n",
    "\n",
    "- 그동안 보통 `pd.read_csv()`를 사용했었는데 Numpy로도 파일을 불러올 수 있었다.\n",
    "\n",
    "\n",
    "- 데이터는 값만 있고 피처명은 없으나 마지막 컬럼이 생존 혹은 사망을 나타내는 타겟이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f810ab31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a94f75",
   "metadata": {},
   "source": [
    "- 총 470개의 샘플이 17개의 피처, 1개의 타겟으로 이루어져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1adaa43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처, 타겟 분리\n",
    "X = Data_set[:,:17]\n",
    "Y = Data_set[:,17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b3671",
   "metadata": {},
   "source": [
    "- 피처와 타겟은 따로 분리해두자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd6c5e",
   "metadata": {},
   "source": [
    "## 10.2 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfeb1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# 시드 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 딥러닝 구조 결정\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 17, activation=\"relu\")) # 입력 값으로 17개의 피처 모두 사용\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f0571",
   "metadata": {},
   "source": [
    "- 케라스에서는 `Sequential()`을 이용해 쉽게 층을 생성할 수 있다.\n",
    "\n",
    "\n",
    "- `Sequential()`의 `add()`를 사용하면 새로운 층을 하나씩 추가한다.\n",
    "\n",
    "\n",
    "- 각 층의 구체적인 구조는 `Dense()`를 이용해 결정한다.\n",
    "\n",
    "\n",
    "- 맨 마지막 층은 출력층이 되며 나머지는 모두 은닉층 역할을 담당한다.\n",
    "\n",
    "\n",
    "- 입력층은 따로 생성하지 않고 첫 번째 `Dense()`에 `input_dim`으로 입력 값의 개수를 정해준다.\n",
    "\n",
    "\n",
    "- 첫 번째 은닉층의 `Dense()`는 17개의 입력 값을 받아 30개의 노드를 생성하며 활성화 함수로 렐루 함수를 사용한다.\n",
    "\n",
    "\n",
    "- 두 번째 출력층의 `Dense()`는 1개의 노드를 생성하며 활성화 함수로 시그모이드 함수를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c9c0f",
   "metadata": {},
   "source": [
    "## 10.3 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4b4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2f9f9",
   "metadata": {},
   "source": [
    "- `compile()`은 앞서 설정한 모델이 효과적으로 구현되게끔 여러가지 환경을 설정한다.\n",
    "\n",
    "\n",
    "- 오차 함수, 최적화 방법, 모델 수행 결과 평가 지표 등을 설정 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ad59f",
   "metadata": {},
   "source": [
    "## 10.4 오차 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18b5e3",
   "metadata": {},
   "source": [
    "앞서 컴파일에 사용할 수 있는 오차 함수의 종류에 대해 조금 더 살펴보자.\n",
    "\n",
    "현재는 MSE를 사용하였지만 교차 엔트로피 계열의 함수 등 다양한 오차 함수가 있다.\n",
    "\n",
    "오차 함수를 바꿔줌에 따라 성능이 더 좋아지기도 한다.\n",
    "\n",
    "지금 데이터는 생존/사망 이진 분류 문제인데 이런 경우는 보통 이항 교차 엔트로피를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450de10d",
   "metadata": {},
   "source": [
    "아래는 오차 함수에 대해 일부 요약해두었다.\n",
    "\n",
    "- **mean_squared_error**: 평균 제곱 오차\n",
    "\n",
    "\n",
    "- **mean_absolute_error**: 평균 절대 오차(실제 값과 예측 값 차이의 절댓값 평균)\n",
    "\n",
    "\n",
    "- **mean_absolute_percentage_error**: 평균 절대 백분율 오차(절대값 오차를 절대값으로 나눈 후 평균)\n",
    "\n",
    "\n",
    "- **mean_squared_logarithmic_error**: 평균 제곱 로그 오차(실제 값과 예측 값에 로그를 적용한 값의 차이를 제곱한 값의 평균)\n",
    "\n",
    "\n",
    "- **categorical_crossentropy**: 범주형 교차 엔트로피(일반적인 분류)\n",
    "\n",
    "\n",
    "- **binary_crossentropy**: 이항 교차 엔트로피(두 개의 클래스 중에서 예측할 때)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c0e77",
   "metadata": {},
   "source": [
    "## 10.5 모델 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d327fee9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 1s 1ms/sample - loss: 0.1495 - accuracy: 0.8404\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 126us/sample - loss: 0.1447 - accuracy: 0.8511\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 121us/sample - loss: 0.1448 - accuracy: 0.8511\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 125us/sample - loss: 0.1453 - accuracy: 0.8489\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 120us/sample - loss: 0.1438 - accuracy: 0.8511\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 126us/sample - loss: 0.1418 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 132us/sample - loss: 0.1425 - accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 124us/sample - loss: 0.1427 - accuracy: 0.8468\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 123us/sample - loss: 0.1446 - accuracy: 0.8489\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 117us/sample - loss: 0.1427 - accuracy: 0.8511\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 123us/sample - loss: 0.1429 - accuracy: 0.8511\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 114us/sample - loss: 0.1419 - accuracy: 0.8511\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 113us/sample - loss: 0.1424 - accuracy: 0.8489\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 124us/sample - loss: 0.1431 - accuracy: 0.8489\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 117us/sample - loss: 0.1422 - accuracy: 0.8404\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 128us/sample - loss: 0.1405 - accuracy: 0.8511\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 123us/sample - loss: 0.1390 - accuracy: 0.8489\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 122us/sample - loss: 0.1398 - accuracy: 0.8383\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 117us/sample - loss: 0.1446 - accuracy: 0.8489\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 142us/sample - loss: 0.1426 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 130us/sample - loss: 0.1410 - accuracy: 0.8511\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 125us/sample - loss: 0.1396 - accuracy: 0.8532\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.84 - 0s 123us/sample - loss: 0.1334 - accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 185us/sample - loss: 0.1362 - accuracy: 0.8489\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 231us/sample - loss: 0.1422 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 230us/sample - loss: 0.1407 - accuracy: 0.8489\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 217us/sample - loss: 0.1387 - accuracy: 0.8532\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 247us/sample - loss: 0.1387 - accuracy: 0.8489\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 229us/sample - loss: 0.1339 - accuracy: 0.8511\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 223us/sample - loss: 0.1376 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 218us/sample - loss: 0.1349 - accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 210us/sample - loss: 0.1296 - accuracy: 0.8532\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 219us/sample - loss: 0.1283 - accuracy: 0.8511\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 218us/sample - loss: 0.1321 - accuracy: 0.8489\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 239us/sample - loss: 0.1411 - accuracy: 0.8532\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 220us/sample - loss: 0.1388 - accuracy: 0.8511\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 217us/sample - loss: 0.1369 - accuracy: 0.8489\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 219us/sample - loss: 0.1372 - accuracy: 0.8468\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 228us/sample - loss: 0.1333 - accuracy: 0.8511\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 220us/sample - loss: 0.1290 - accuracy: 0.8511\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 217us/sample - loss: 0.1276 - accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 218us/sample - loss: 0.1383 - accuracy: 0.8532\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 239us/sample - loss: 0.1367 - accuracy: 0.8532\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 227us/sample - loss: 0.1317 - accuracy: 0.8532\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 213us/sample - loss: 0.1327 - accuracy: 0.8553\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 226us/sample - loss: 0.1259 - accuracy: 0.8511\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 222us/sample - loss: 0.1258 - accuracy: 0.8553\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 219us/sample - loss: 0.1359 - accuracy: 0.8532\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 212us/sample - loss: 0.1329 - accuracy: 0.8426\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 218us/sample - loss: 0.1362 - accuracy: 0.8489\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 233us/sample - loss: 0.1400 - accuracy: 0.8511\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 214us/sample - loss: 0.1407 - accuracy: 0.8511\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 208us/sample - loss: 0.1373 - accuracy: 0.8511\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 243us/sample - loss: 0.1314 - accuracy: 0.8426\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 244us/sample - loss: 0.1305 - accuracy: 0.8532\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 226us/sample - loss: 0.1303 - accuracy: 0.8574\n",
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 217us/sample - loss: 0.1338 - accuracy: 0.8511\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 243us/sample - loss: 0.1364 - accuracy: 0.8532\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 223us/sample - loss: 0.1280 - accuracy: 0.8489\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 224us/sample - loss: 0.1321 - accuracy: 0.8532\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 215us/sample - loss: 0.1405 - accuracy: 0.8511\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 246us/sample - loss: 0.1226 - accuracy: 0.8553\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 225us/sample - loss: 0.1402 - accuracy: 0.8447\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 212us/sample - loss: 0.1388 - accuracy: 0.8532\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 220us/sample - loss: 0.1366 - accuracy: 0.8574\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 226us/sample - loss: 0.1344 - accuracy: 0.8596\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 226us/sample - loss: 0.1246 - accuracy: 0.8617\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 250us/sample - loss: 0.1264 - accuracy: 0.8574\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 202us/sample - loss: 0.1292 - accuracy: 0.8532\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 220us/sample - loss: 0.1306 - accuracy: 0.8511\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 217us/sample - loss: 0.1290 - accuracy: 0.8574\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 214us/sample - loss: 0.1282 - accuracy: 0.8426\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 225us/sample - loss: 0.1245 - accuracy: 0.8596\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 241us/sample - loss: 0.1231 - accuracy: 0.8532\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 221us/sample - loss: 0.1228 - accuracy: 0.8574\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 208us/sample - loss: 0.1218 - accuracy: 0.8532\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 252us/sample - loss: 0.1249 - accuracy: 0.8574\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 247us/sample - loss: 0.1341 - accuracy: 0.8489\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.85 - 0s 236us/sample - loss: 0.1318 - accuracy: 0.8511\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 302us/sample - loss: 0.1316 - accuracy: 0.8468\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 259us/sample - loss: 0.1210 - accuracy: 0.8574\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 218us/sample - loss: 0.1229 - accuracy: 0.8553\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 242us/sample - loss: 0.1234 - accuracy: 0.8553\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 238us/sample - loss: 0.1236 - accuracy: 0.8468\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 225us/sample - loss: 0.1277 - accuracy: 0.8489\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 240us/sample - loss: 0.1254 - accuracy: 0.8553\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 221us/sample - loss: 0.1310 - accuracy: 0.8553\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 219us/sample - loss: 0.1220 - accuracy: 0.8511\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 238us/sample - loss: 0.1202 - accuracy: 0.8532\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 238us/sample - loss: 0.1233 - accuracy: 0.8553\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 220us/sample - loss: 0.1194 - accuracy: 0.8553\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 256us/sample - loss: 0.1175 - accuracy: 0.8574\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 226us/sample - loss: 0.1376 - accuracy: 0.8447\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 235us/sample - loss: 0.1321 - accuracy: 0.8596\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 238us/sample - loss: 0.1300 - accuracy: 0.8638\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 221us/sample - loss: 0.1215 - accuracy: 0.8511\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 238us/sample - loss: 0.1213 - accuracy: 0.8596\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 243us/sample - loss: 0.1303 - accuracy: 0.8447\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 215us/sample - loss: 0.1199 - accuracy: 0.8638\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 240us/sample - loss: 0.1192 - accuracy: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad842c5208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f1b9c6",
   "metadata": {},
   "source": [
    "- 마지막으로 `fit()`을 이용해 모델을 실행할 수 있다.\n",
    "\n",
    "\n",
    "- `epochs`는 지정한 숫자 만큼 샘플이 재사용 될 때 까지 반복하라는 뜻이다.\n",
    "\n",
    "\n",
    "- `batch_size`는 한번에 사용할 샘플 수를 정한다.\n",
    "\n",
    "\n",
    "- 즉 한 epoch 마다 모든 샘플을 사용하긴 하지만 batch_size 만큼 나누어서 집어 넣는다.\n",
    "\n",
    "\n",
    "- [딥러닝의 동작 원리[로지스틱회귀]](https://romg2.github.io/dl_all/02-%EB%AA%A8%EB%91%90%EC%9D%98-%EB%94%A5%EB%9F%AC%EB%8B%9D-02.-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98-%EB%8F%99%EC%9E%91-%EC%9B%90%EB%A6%AC-(2)/)에서 경사하강법 코드로 예를 들면 교재는 batch_size를 1 나는 470, epoch는 동일하게 2001로 설정하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
